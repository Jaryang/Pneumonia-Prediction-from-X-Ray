{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd354e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ffe49",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ab8631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = './data/chest_xray/'\n",
    "train_path = './data/chest_xray/'\n",
    "val_path = './data/chest_xray/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c700420",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_info = pd.read_csv('img_info.csv')\n",
    "test_df = img_info.loc[img_info.loc[:, 'data'] == 'Test']\n",
    "train_df = img_info.loc[img_info.loc[:, 'data'] == 'Train']\n",
    "val_df = test_df = img_info.loc[img_info.loc[:, 'data'] == 'Validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae3cb87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Normal Images in the Training Data: 0.5093694606229425\n",
      "Percentage of Pneumonia Images in the Training Data: 0.4906305393770575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rs/dwj3n8716t593gn_r4x21y0r0000gn/T/ipykernel_79588/2152691127.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  normal_images.loc[:,'imbalance'] = 1\n"
     ]
    }
   ],
   "source": [
    "# Apply data augmentaion to solve the imbance problem\n",
    "normal_images = train_df.loc[train_df.loc[:,'label'] == 0]\n",
    "normal_images.loc[:,'imbalance'] = 1\n",
    "train_df = pd.concat([train_df, normal_images, normal_images]).reset_index(drop=True)\n",
    "print('Percentage of Normal Images in the Training Data: {}'.format(\n",
    "    len(train_df.loc[train_df.loc[:,'label'] == 0])/len(train_df.loc[:,'label'])))\n",
    "print('Percentage of Pneumonia Images in the Training Data: {}'.format(\n",
    "    len(train_df.loc[train_df.loc[:,'label'] == 1])/len(train_df.loc[:,'label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4709732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, df, img_dir_path, transforms=None):\n",
    "        \"\"\"\n",
    "        You can set your custom dataset to take in more parameters than specified\n",
    "        here. But, I recommend at least you start with the three I listed here,\n",
    "        as these are standard\n",
    "\n",
    "        csv_file (str): file path to the csv file you created /\n",
    "        df (pandas df): pandas dataframe\n",
    "\n",
    "        img_dir_path: directory path to your images\n",
    "        transform: Compose (a PyTorch Class) that strings together several\n",
    "          transform functions (e.g. data augmentation steps)\n",
    "\n",
    "        One thing to note -- you technically could implement `transform` within\n",
    "        the dataset. No one is going to stop you, but you can think of the\n",
    "        transformations/augmentations you do as a hyperparameter. If you treat\n",
    "        it as a hyperparameter, you want to be able to experiment with different\n",
    "        transformations, and therefore, it would make more sense to decide those\n",
    "        transformations outside the dataset class and pass it to the dataset!\n",
    "        \"\"\"\n",
    "        self.img_labels = df\n",
    "        self.img_dir = img_dir_path\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns: (int) length of your dataset\n",
    "        \"\"\"\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Loads and returns your sample (the image and the label) at the\n",
    "        specified index\n",
    "\n",
    "        Parameter: idx (int): index of interest\n",
    "\n",
    "        Returns: image, label\n",
    "        \"\"\"\n",
    "\n",
    "        img_path =  self.img_dir + self.img_labels.iloc[idx, 1]\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        label = self.img_labels.iloc[idx, -1]\n",
    "        \n",
    "        imbalance = self.img_labels.iloc[idx, -2]\n",
    "\n",
    "        if self.transforms:\n",
    "            \n",
    "            if imbalance and not label:\n",
    "                image = transforms(image)\n",
    "                image = imbalance_transform(image)\n",
    "                \n",
    "            else:\n",
    "                image = transforms(image)\n",
    "        else:\n",
    "            image = tranform_test(image)\n",
    "               \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e902f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.Compose(\n",
    "    [\n",
    "        T.Resize((224,224), antialias=None, interpolation=InterpolationMode.BICUBIC),\n",
    "        T.RandomApply([\n",
    "            T.GaussianBlur(kernel_size=(5,5), sigma=(0.1, 0.2))\n",
    "        ], p=0.5),\n",
    "        T.RandomEqualize(),\n",
    "        T.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "tranform_test = T.Compose(\n",
    "    [\n",
    "        T.Resize((224,224), antialias=None, interpolation=InterpolationMode.BICUBIC),\n",
    "        T.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "imbalance_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(degrees=10),\n",
    "    T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    T.RandomErasing(p=0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d00156bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = CustomImageDataset(train_df, train_path, transforms=transforms)\n",
    "val_data = CustomImageDataset(val_df, val_path, transforms=transforms)\n",
    "test_data = CustomImageDataset(test_df, test_path, transforms=None)\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e36bfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0784, 0.0941, 0.0941,  ..., 0.0902, 0.0980, 0.0275],\n",
       "          [0.0784, 0.0941, 0.0941,  ..., 0.0941, 0.0941, 0.0275],\n",
       "          [0.0745, 0.0941, 0.0980,  ..., 0.0941, 0.0941, 0.0275],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0118, 0.0118, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0784, 0.0941, 0.0941,  ..., 0.0902, 0.0980, 0.0275],\n",
       "          [0.0784, 0.0941, 0.0941,  ..., 0.0941, 0.0941, 0.0275],\n",
       "          [0.0745, 0.0941, 0.0980,  ..., 0.0941, 0.0941, 0.0275],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0118, 0.0118, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0784, 0.0941, 0.0941,  ..., 0.0902, 0.0980, 0.0275],\n",
       "          [0.0784, 0.0941, 0.0941,  ..., 0.0941, 0.0941, 0.0275],\n",
       "          [0.0745, 0.0941, 0.0980,  ..., 0.0941, 0.0941, 0.0275],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0118, 0.0118, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73506067",
   "metadata": {},
   "source": [
    "## Model Setup - more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00eee4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20fea7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_dataloader, val_dataloader, scheduler=None, EPOCHS=25):\n",
    "    \"\"\"\n",
    "    Train the model and return relevant accuracy metric\n",
    "    \n",
    "    Input:\n",
    "        model: the defined neural network\n",
    "        criterion: the defined loss func\n",
    "        optimizer: the defined optimizer\n",
    "        scheduler: if specified, the learning rate is going to decrease with each epoch\n",
    "        train_dataloader & val_dataloader: DataLoader object\n",
    "        EPOCHS: int\n",
    "    Output:\n",
    "        model: trained model\n",
    "        train_losses, train_accuracies, val_losses, val_accuracies: acc metrics\n",
    "    \"\"\"\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    learning_rate = []\n",
    "\n",
    "    for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "\n",
    "        # TRAIN\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_matched = 0\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data           # NOTE: depending on how you implemented your dataset class's __getitem__ it could be labels, inputs\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # keep track of the loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # CALCULATE ACCURACY METRIC\n",
    "            preds = torch.argmax(outputs, dim = 1)  # Find out the predicted class with the highest prob\n",
    "            running_matched += torch.sum(preds == labels.data) # caculate the number of matched labels\n",
    "\n",
    "        avg_train_loss = running_loss / (i + 1)     # i + 1 gives us the total number of batches in train dataloader\n",
    "        avg_train_acc = running_matched.double() / len(train_dataloader.dataset)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracies.append(avg_train_acc)\n",
    "\n",
    "        # VALIDATE\n",
    "        # In the validation part, we don't want to keep track of the gradients \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        running_val_matched = 0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_dataloader):\n",
    "                inputs, labels = data\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # keep track of the loss\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "                # CALCULATE ACCURACY METRIC\n",
    "                preds = torch.argmax(outputs, dim = 1)\n",
    "                running_val_matched += torch.sum(preds == labels.data)\n",
    "\n",
    "        avg_val_loss = running_val_loss / (i + 1)\n",
    "        avg_val_acc = running_val_matched.double() / len(val_dataloader.dataset)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracies.append(avg_val_acc)\n",
    "        learning_rate.append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        if scheduler != None:\n",
    "            scheduler.step(avg_val_loss) # add a scheduler to reduce the lr\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f} | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f} | \"\n",
    "              f\"learning rate: {optimizer.param_groups[0]['lr']:.4f}\")\n",
    "        \n",
    "        \n",
    "    return model, train_losses, train_accuracies, val_losses, val_accuracies, learning_rate\n",
    "\n",
    "\n",
    "def test(model, test_dataloader):\n",
    "    \"\"\"\n",
    "    Test the data and return test accuracy\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_test_matched = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_dataloader):\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim = 1)\n",
    "            running_test_matched += torch.sum(preds == labels.data)\n",
    "    \n",
    "        test_acc = running_test_matched.double() / len(test_dataloader.dataset)\n",
    "        print(f\"Test accuracy: {float(test_acc):.4f}\")\n",
    "\n",
    "    return test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33af4cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def write_model_and_results(model, \n",
    "                            train_losses, \n",
    "                            train_accuracies, \n",
    "                            val_losses, \n",
    "                            val_accuracies,\n",
    "                            learning_rate,\n",
    "                            path):\n",
    "    \"\"\"\n",
    "    Save the model and results\n",
    "    \n",
    "    Inputs:\n",
    "        path: a list of str containing the path for model and the path for results\n",
    "    \"\"\"\n",
    "\n",
    "    train_acc = [float(i) for i in train_accuracies]\n",
    "    val_acc = [float(i) for i in val_accuracies]\n",
    "\n",
    "    result = {'train_losses': train_losses,\n",
    "             'train_accuracies': train_acc,\n",
    "             'val_losses': val_losses,\n",
    "             'val_accuracies': val_acc,\n",
    "             'learning_rates': learning_rate}\n",
    "    \n",
    "    # save model\n",
    "    torch.save(model.state_dict(), path[0])\n",
    "    # save results\n",
    "    with open(path[1], 'w') as f:\n",
    "        f.write(json.dumps(result))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163e19a",
   "metadata": {},
   "source": [
    "### Sample Model Construction\n",
    "\n",
    "Here shows the training precess for the CNN with ReLU as the activation function and Negative Loss Likelihood as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9197b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNeuralNetwork_relu(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.6):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.LeNet = nn.Sequential(     \n",
    "            # convolutional layers            \n",
    "            nn.Sequential(                                            # FIRST LAYER: (INPUT LAYER)\n",
    "              nn.Conv2d(3, 6, kernel_size=3, stride=1, padding=0),    # CONVOLUTION \n",
    "              nn.BatchNorm2d(6),\n",
    "              nn.ReLU(),\n",
    "              nn.Dropout(p=dropout_rate),\n",
    "              nn.MaxPool2d(kernel_size = 2, stride = 2)),             # POOLING\n",
    "           \n",
    "            nn.Sequential(                                            # SECOND LAYER: HIDDEN LAYER 1\n",
    "              nn.Conv2d(6, 16, kernel_size=3, stride=1, padding=0),   # CONVOLUTION \n",
    "              nn.BatchNorm2d(16),\n",
    "              nn.ReLU(),\n",
    "              nn.Dropout(p=dropout_rate),\n",
    "              nn.MaxPool2d(kernel_size = 2, stride = 2)),             # POOLING\n",
    "            \n",
    "          # POOLING\n",
    "            # fully connected layers\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.Linear(16 * 54 * 54, 256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(256, 32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            \n",
    "        # output layer\n",
    "            nn.Linear(32, 2)                                            # OUTPUT LAYER\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.LeNet(x)\n",
    "        return F.log_softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c8e0816",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relu = CustomNeuralNetwork_relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cceffe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model_relu.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Inspired by: https://hasty.ai/docs/mp-wiki/scheduler/reducelronplateau\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                 mode='min', \n",
    "                                                 factor=0.5, \n",
    "                                                 patience=2, \n",
    "                                                 threshold=0.0001, \n",
    "                                                 threshold_mode='rel', \n",
    "                                                 cooldown=0, \n",
    "                                                 min_lr=0, \n",
    "                                                 eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7f9c3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 | Train Loss: 0.1929, Train Acc: 0.9261 | Val Loss: 0.4966, Val Acc: 0.8125 | learning rate: 0.0010\n",
      "Epoch 2/15 | Train Loss: 0.0900, Train Acc: 0.9649 | Val Loss: 0.4497, Val Acc: 0.8125 | learning rate: 0.0010\n",
      "Epoch 3/15 | Train Loss: 0.0676, Train Acc: 0.9748 | Val Loss: 0.3373, Val Acc: 0.9375 | learning rate: 0.0010\n",
      "Epoch 4/15 | Train Loss: 0.0639, Train Acc: 0.9764 | Val Loss: 0.4021, Val Acc: 0.8750 | learning rate: 0.0010\n",
      "Epoch 5/15 | Train Loss: 0.0459, Train Acc: 0.9828 | Val Loss: 0.3155, Val Acc: 0.9375 | learning rate: 0.0010\n",
      "Epoch 6/15 | Train Loss: 0.0416, Train Acc: 0.9851 | Val Loss: 0.3383, Val Acc: 0.8750 | learning rate: 0.0010\n",
      "Epoch 7/15 | Train Loss: 0.0413, Train Acc: 0.9853 | Val Loss: 0.3977, Val Acc: 0.8125 | learning rate: 0.0010\n",
      "Epoch 8/15 | Train Loss: 0.0375, Train Acc: 0.9863 | Val Loss: 0.3414, Val Acc: 0.9375 | learning rate: 0.0005\n",
      "Epoch 9/15 | Train Loss: 0.0242, Train Acc: 0.9914 | Val Loss: 0.3963, Val Acc: 0.8750 | learning rate: 0.0005\n",
      "Epoch 10/15 | Train Loss: 0.0218, Train Acc: 0.9929 | Val Loss: 0.3611, Val Acc: 0.8750 | learning rate: 0.0005\n",
      "Epoch 11/15 | Train Loss: 0.0192, Train Acc: 0.9942 | Val Loss: 0.2350, Val Acc: 0.8125 | learning rate: 0.0005\n",
      "Epoch 12/15 | Train Loss: 0.0195, Train Acc: 0.9938 | Val Loss: 0.2811, Val Acc: 0.8125 | learning rate: 0.0005\n",
      "Epoch 13/15 | Train Loss: 0.0218, Train Acc: 0.9918 | Val Loss: 0.2412, Val Acc: 0.9375 | learning rate: 0.0005\n",
      "Epoch 14/15 | Train Loss: 0.0163, Train Acc: 0.9933 | Val Loss: 0.2763, Val Acc: 0.8750 | learning rate: 0.0003\n",
      "Epoch 15/15 | Train Loss: 0.0143, Train Acc: 0.9951 | Val Loss: 0.2327, Val Acc: 0.9375 | learning rate: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# I interupt running after this first epoch, feel free to continue run it\n",
    "model_relu, train_losses, train_accuracies, val_losses, val_accuracies, learning_rate = train(model_relu, \n",
    "                                                                                              criterion, \n",
    "                                                                                              optimizer,\n",
    "                                                                                              train_dataloader, \n",
    "                                                                                              val_dataloader, \n",
    "                                                                                              scheduler,\n",
    "                                                                                              EPOCHS=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae79d492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8125, dtype=torch.float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model_relu, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "add23258",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict\n",
    "acc_dict_5L = {0.8125: 14, 0.875: 40, 0.9375: 35,1.0: 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42979fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ['model_new_5L.PT', 'result_new_5L.txt']\n",
    "write_model_and_results(model_relu, train_losses, train_accuracies, val_losses, val_accuracies, learning_rate,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc24b734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = acc_dict_5L\n",
    "names = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "plt.bar(range(len(data)), values, tick_label=names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2001de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data =  {0.8125:0, 0.875: 41, 0.9375: 59, 1:0}\n",
    "names = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "plt.bar(range(len(data)), values, tick_label=names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a903480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data =  {0.8125:0, 0.875: 41, 0.9375: 59, 1:0}\n",
    "X = acc_dict_5L.keys()\n",
    "layer_5 = acc_dict_5L.values()\n",
    "layer_3 = data.values()\n",
    "  \n",
    "X_axis = np.arange(len(X))\n",
    "  \n",
    "plt.bar(X_axis - 0.2, layer_5, 0.4, label = '5 layer')\n",
    "plt.bar(X_axis + 0.2, layer_3, 0.4, label = '3 layer')\n",
    "  \n",
    "plt.xticks(X_axis, X)\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3784275",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e08975a",
   "metadata": {},
   "source": [
    "**Note:** We incorporate all the accuracy metrics generated by the trained models into two files: CNN_crossentropy_output.txt and CNN_NLL_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912c805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
